module LiPoSID

using LinearAlgebra
using QuantumOptics

using DynamicPolynomials
# using MomentTools
#using MosekTools
using Random
using JuMP
using NLopt
#using TSSOS
#using Clustering
using HDF5

using Optim

#using HomotopyContinuation

function hankel(y::AbstractArray)
    m, time_duration = size(y) # m - dimention of output vector y, time_duration - length of timeseries (number of time steps)
    q = Int(round(time_duration/2)) # q - is the size of Hankel matrix 
    H = zeros(eltype(y), q * m , q) 
    for r = 1:q, c = 1:q # r - rows, c -columns
        H[(r-1)*m+1:r*m, c] = y[:, r+c-1]
    end
    return H, m
end

function lsid_ACx0(Y::AbstractArray, Œît) #, Œ¥ = 1e-6)
    # y - output time series dim[y] = m x number_of_time_steps
    # Œ¥ - precission cutoff all the smaller values of Œ£ will be discarded 
    
    H, m = hankel(Y) # Hankel matrix and dimention of output (should be 12 in our case)
    U, Œ£, Vd = svd(H) # Singular value decomposition of H to U,  Œ£,  V‚Ä†
    
    s = Diagonal(sqrt.(Œ£)) # Matrix square root 
    U = U * s
    Vd = s * Vd
     
    # n = argmin(abs.(Œ£/maximum(Œ£) .- Œ¥)) - 1 # estimated rank of the system

    Sigma_log = log.(Œ£/maximum(Œ£))
    Sigma2D = reshape(Sigma_log, (1, length(Sigma_log)))

    n = minimum(counts(kmeans(Sigma2D, 2))) + 1
    
    C = U[1:m, 1:n] # m -dimention of output, n - rank of the system
    
    U_up = U[1:end-m, :] # U‚Üë
    U_down = U[m+1:end, :] # U‚Üì
    
    A = pinv(U_up) * U_down
    # Ac = log(A)/Œît 
    # Ac = Ac[1:n, 1:n] 
    A = A[1:n, 1:n] # n - estimated rank of the system
    
    x0 = pinv(U) * H
    x0 = x0[1:n, 1]
    
    return A, C, x0 # was A, Ac, C, x0

end

function lsid_n_ACx0(Y::AbstractArray, Œît, n) 
    # y - output time series dim[y] = m x number_of_time_steps
    # n - rank of the system we want to identify
    
    H, m = hankel(Y) # Hankel matrix and dimention of output (should be 12 in our case)
    U, Œ£, Vd = svd(H) # Singular value decomposition of H to U,  Œ£,  V‚Ä†
    
    s = Diagonal(sqrt.(Œ£)) # Matrix square root 
    U = U * s
    Vd = s * Vd
      
    C = U[1:m, 1:n] # m -dimention of output, n - rank of the system
    
    U_up = U[1:end-m, :] # U‚Üë
    U_down = U[m+1:end, :] # U‚Üì
    
    A = pinv(U_up) * U_down
    # Ac = log(A)/Œît 
    # Ac = Ac[1:n, 1:n] 
    A = A[1:n, 1:n] # n - estimated rank of the system
    
    x0 = pinv(U) * H
    x0 = x0[1:n, 1]
    
    return A, C, x0 # was A, Ac, C, x0

end

function lsid_n_ACx0Œ£(Y::AbstractArray, Œît, n) 
    # y - output time series dim[y] = m x number_of_time_steps
    # n - rank of the system we want to identify
    
    H, m = hankel(Y) # Hankel matrix and dimention of output (should be 12 in our case)
    U, Œ£, Vd = svd(H) # Singular value decomposition of H to U,  Œ£,  V‚Ä†
    
    s = Diagonal(sqrt.(Œ£)) # Matrix square root 
    U = U * s
    Vd = s * Vd
      
    C = U[1:m, 1:n] # m -dimention of output, n - rank of the system
    
    U_up = U[1:end-m, :] # U‚Üë
    U_down = U[m+1:end, :] # U‚Üì
    
    A = pinv(U_up) * U_down
    # Ac = log(A)/Œît 
    # Ac = Ac[1:n, 1:n] 
    A = A[1:n, 1:n] # n - estimated rank of the system
    
    x0_1 = pinv(U) * H
    x0_1 = x0_1[1:n, 1]
    
    x0_2= Vd[1:n, 1]
    
    # Y0 = [1.0   0.0  -0.0   0.0   0.0  -0.0   0.5   0.5  -0.0   0.5   0.0   0.5 ]'
    Y0 = Y[:,1]

    try
        global x0_3 = (C\Y0)[1:n, 1]
    catch
        global x0_3 = zeros(n)
    end

    x0_list = [x0_1, x0_2, x0_3]
       
    norms = [norm(Y0 - C*x0_i) for x0_i in x0_list]
   
    x0 = x0_list[argmin(norms)]
    
    return A, C, x0, Œ£

end


function lsid_n_ACx0Œ£_old(Y::AbstractArray, Œît, n) 
    # y - output time series dim[y] = m x number_of_time_steps
    # n - rank of the system we want to identify
    
    H, m = hankel(Y) # Hankel matrix and dimention of output (should be 12 in our case)
    U, Œ£, Vd = svd(H) # Singular value decomposition of H to U,  Œ£,  V‚Ä†
    
    s = Diagonal(sqrt.(Œ£)) # Matrix square root 
    U = U * s
    Vd = s * Vd
      
    C = U[1:m, 1:n] # m -dimention of output, n - rank of the system
    
    U_up = U[1:end-m, :] # U‚Üë
    U_down = U[m+1:end, :] # U‚Üì
    
    A = pinv(U_up) * U_down
    # Ac = log(A)/Œît 
    # Ac = Ac[1:n, 1:n] 
    A = A[1:n, 1:n] # n - estimated rank of the system
    
    x0 = pinv(U) * H
    x0 = x0[1:n, 1]
    
    return A, C, x0, Œ£

end

function propagate(A, x0, steps)
    
    x = []
    push!(x, x0)

    @assert size(x0,1) == size(A,1) == size(A,2)

    for i=2:steps
        push!(x, A * x[end])
    end

    return x
end 

function propagate(A, C, x0, steps)
    n = size(A, 1)
    @assert size(x0,1) == n
    y = zeros(size(C,1), steps) 
    x‚Çú = x0
    for t in 1:steps
        y[:, t] = C * x‚Çú
        x‚Çú = A * x‚Çú
    end
    return y
end 

function propagate_LTI(A, C, x‚ÇÄ, n, steps)
    @assert n <= size(A,  1)
    @assert n <= size(x‚ÇÄ, 1)
    y = zeros(size(C,1), steps) 
    x‚Çú = x‚ÇÄ[1:n]
    for t in 1:steps
        y[:, t] = C[:,1:n] * x‚Çú
        x‚Çú = A[1:n,1:n] * x‚Çú
    end
    return y
end 

function rand_dm(n)
    # return a random density matrix
    œÅ = -1 .+ 2 * rand(n, n) 
    œÅ += im * (-1 .+ 2 * rand(n, n))  
    œÅ = œÅ * œÅ'
    Hermitian(œÅ / tr(œÅ))
end

function rand_herm(n)
    # return a random hermitian matrix
    h = -1 .+ 2 * rand(n, n)
    h += im *(-1 .+ 2 *  rand(n, n))
    h = 0.5 * (h + h')
    Hermitian(h)
end

function bloch(œÅ::Matrix{ComplexF64})
    # Pauli matricies
    œÉ = [ [0 1; 1 0], [0 -im; im 0], [1 0; 0 -1], [1 0; 0 1] ]   
    #bloch_vec = [real(tr(œÉ·µ¢ * œÅ)) for œÉ·µ¢ in œÉ[2:end]]
    bloch_vec = [real(tr(œÉ·µ¢ * œÅ)) for œÉ·µ¢ in œÉ[1:3]]
end

function bloch(œÅ_list::Union{Vector{Any},Vector{Matrix{ComplexF64}}})
    # œÅ_list::Vector{Matrix{ComplexF64}}
    # Pauli matricies
    œÉ = [ [0 1; 1 0], [0 -im; im 0], [1 0; 0 -1], [1 0; 0 1] ]
    
    time_steps = length(œÅ_list)
    bloch_vec = zeros(3, time_steps)
    for t in 1:time_steps
        bloch_vec[:, t] = [real(tr(œÉ[i] * œÅ_list[t])) for i=1:3] # 2 ???
    end
    convert.(Float64, bloch_vec)
end

function bloch(œÅ_list::Vector{Any})#Vector{Hermitian{ComplexF64, Matrix{ComplexF64}}})
    # Pauli matricies
    œÉ = [ [0 1; 1 0], [0 -im; im 0], [1 0; 0 -1], [1 0; 0 1] ]
    time_steps = length(œÅ_list)
    bloch_vec = zeros(3, time_steps)
    for t in 1:time_steps
        bloch_vec[:, t] = [real(tr(œÉ[i] * œÅ_list[t])) for i=1:3] # 2 ???
    end
    convert.(Float64, bloch_vec)
end

function rho_from_bloch(bloch_vec::Vector{Float64})
    # Pauli matricies
    œÉ = [ [0 1; 1 0], [0 -im; im 0], [1 0; 0 -1], [1 0; 0 1] ]
    œÅ = (sum([bloch_vec[i] * œÉ[i] for i=1:3]) + I)/2 
    œÅ ::Matrix{ComplexF64}
end

function rho_series_from_bloch(bloch_vec::Matrix{Float64})
    time_steps = size(bloch_vec, 2)
    œÅ = Vector{Matrix{ComplexF64}}() # size !!!
    for t in 1:time_steps
        push!(œÅ, rho_from_bloch(bloch_vec[:, t]))     
    end
    œÅ ::Vector{Matrix{ComplexF64}}
end

function rho3d_from_bloch(bloch_vec::Matrix{Float64})
    œÉ = [ [0 1; 1 0], [0 -im; im 0], [1 0; 0 -1], [1 0; 0 1] ]
    time_steps = size(bloch_vec, 2)
    œÅ = zeros(2, 2, time_steps) + im*zeros(2, 2, time_steps)
    for t in 1:time_steps
        œÅ[:, :, t] = (sum([bloch_vec[i, t] * œÉ[i] for i=1:3]) + I)/2       
    end
    œÅ ::Array{ComplexF64, 3}
end

function rand_Linblad_w_noise(basis, seed, w, t_list)
    # seed - to generate reproducable system,
    # w - noise level
    # t_list - time span
    
    # basis = NLevelBasis(2) # define 2-level basis

    n = basis.N

    Random.seed!(seed)    
    
    œÅ‚ÇÄ = DenseOperator(basis, rand_dm(n))  # initial state density matrix
    H = DenseOperator(basis, rand_herm(n)) # Hamiltonian of the system
    J = DenseOperator(basis, (-1 .+ 2 *randn(n, n)) + im*(-1 .+ 2 *randn(n, n))) # Lindblad decipator  was rand !!!!!!
    
    time, œÅ_exact = timeevolution.master(t_list, œÅ‚ÇÄ, H, [J])

    œÅ = [ (1 - w) * œÅ‚Çú.data + w * rand_dm(n) for œÅ‚Çú in œÅ_exact ], H.data, J.data
       
end

function frobenius_norm2(m)
    return tr(m * m')
end

function lindblad_rhs(œÅ, H, J::Matrix)
    """
    Right hand side of the Lindblad master equation
    """
    return -im * (H * œÅ - œÅ * H) + J * œÅ * J' - (J' * J  * œÅ + œÅ * J' * J) / 2
    
end

function lindblad_rhs(œÅ, H, J::Array)
    """
    Right hand side of the Lindblad master equation with multiple dicipators
    """
   
    Œ£ = sum([ ( J‚±º * œÅ * J‚±º' - (J‚±º' * J‚±º  * œÅ + œÅ * J‚±º' * J‚±º)/2 ) for J‚±º in J ])
    
    return -im * (H * œÅ - œÅ * H) + Œ£ 
    
end


function lindblad_rhs(œÅ, H, J::Array, g)
    """
    Right hand side of the Lindblad master equation with multiple dicipators
    """
   
    Œ£ = sum([ ( J‚±º * œÅ * J‚±º' - (J‚±º' * J‚±º  * œÅ + œÅ * J‚±º' * J‚±º)/2 ) for J‚±º in J ])
    
    return -im * (H * œÅ - œÅ * H) + g * Œ£ 
    
end

import Base.real
function real(p::AbstractPolynomial)
    sum(real(coef) * mon for (coef, mon) in zip(coefficients(p), monomials(p))) #if ~isapproxzero(abs(coef)))
end

function pade_obj(œÅ::Array{ComplexF64,3}, t, H, J)
   
    obj = 0
    for i in 2:size(œÅ,3)
        obj += frobenius_norm2(
            œÅ[:, :, i] - œÅ[:, :, i-1] 
            - (t[i]-t[i-1])*lindblad_rhs((œÅ[:, :, i]+œÅ[:, :, i-1])/2, H, J)
        )
    end
    obj = sum(real(coef) * mon for (coef, mon) in zip(coefficients(obj), monomials(obj)))
    return obj
end

function pade_obj(œÅ::Vector{Matrix{ComplexF64}}, t::Vector{Float64}, H, J)

    obj = 0
    for i in 2:size(œÅ,1)
        obj += frobenius_norm2(
            œÅ[i] - œÅ[i-1] 
            - (t[i]-t[i-1])*lindblad_rhs((œÅ[i]+œÅ[i-1])/2, H, J)
        )
    end
    obj = sum(real(coef) * mon for (coef, mon) in zip(coefficients(obj), monomials(obj)))
    return obj
end

function simpson_obj(œÅ::Vector{Matrix{ComplexF64}}, t, H, J)
    
    obj = 0
    for i in 3:length(œÅ)
        obj += frobenius_norm2(
            œÅ[i] - œÅ[i-2] - (t[i]-t[i-1])lindblad_rhs((œÅ[i-2] + 4œÅ[i-1] + œÅ[i])/3, H, J)
        )
    end
    obj = sum(real(coef) * mon for (coef, mon) in zip(coefficients(obj), monomials(obj)))
    return obj
end

function simpson_obj(œÅ::Vector{Matrix{ComplexF64}}, t, H, J, g)
    
    obj = 0
    for i in 3:length(œÅ)
        obj += frobenius_norm2(
            œÅ[i] - œÅ[i-2] - (t[i]-t[i-1])lindblad_rhs((œÅ[i-2] + 4œÅ[i-1] + œÅ[i])/3, H, J, g)
        )
    end
    obj = sum(real(coef) * mon for (coef, mon) in zip(coefficients(obj), monomials(obj)))
    return obj
end

function simpson_obj(œÅ::Array{ComplexF64,3}, t, H, J)  
    
    obj = 0
    for i in 3:length(œÅ)
        obj += frobenius_norm2(
            œÅ[:, :, i] - œÅ[:, :, i-2] - (t[i]-t[i-1])lindblad_rhs((œÅ[:, :, i-2] + 4œÅ[:, :, i-1] + œÅ[:, :, i])/3, H, J)
        )
    end
    obj = sum(real(coef) * mon for (coef, mon) in zip(coefficients(obj), monomials(obj)))
    return obj
end

function simpson_obj_g(œÅ::Array{ComplexF64,3}, t, H, J, g)  
    
    obj = 0
    for i in 3:length(œÅ)
        obj += frobenius_norm2(
            œÅ[:, :, i] - œÅ[:, :, i-2] - (t[i]-t[i-1])lindblad_rhs((œÅ[:, :, i-2] + 4œÅ[:, :, i-1] + œÅ[:, :, i])/3, H, J, g)
        )
    end
    obj = sum(real(coef) * mon for (coef, mon) in zip(coefficients(obj), monomials(obj)))
    return obj
end

function boole_obj(œÅ::Vector{Matrix{ComplexF64}}, t, H, A)
    
    obj = 0
    
    for i in 5:length(œÅ)
        œÅ·µá·µí·µíÀ° = 2(7œÅ[i-4] + 32œÅ[i-3] + 12œÅ[i-3] + 32œÅ[i-2] + 7œÅ[i])/45  
        obj += frobenius_norm2( œÅ[i] - œÅ[i-4] - (t[i]-t[i-1])lindblad_rhs(œÅ·µá·µí·µíÀ°, H, A) )
    end
    
    obj = sum(real(coef) * mon for (coef, mon) in zip(coefficients(obj), monomials(obj)))
    
    return obj

end

function kraus_obj(œÅ::Vector{Matrix{ComplexF64}}, K1, K2) 
    obj = 0
    for i in 1:length(œÅ)-1
        obj += frobenius_norm2(K1 * œÅ[i] * K1' - œÅ[i+1]) + frobenius_norm2(K2 * œÅ[i] * K2' - œÅ[i+1])
    end
    obj = sum(real(coef) * mon for (coef, mon) in zip(coefficients(obj), monomials(obj)))
    return obj
end

function kraus_obj(œÅ, K) 
    obj = 0
    for i in 1:length(œÅ)-1
        obj += LiPoSID.frobenius_norm2(sum(k * œÅ[i] * k' for k in K) - œÅ[i+1])
    end
    return real(obj)
end

function kraus_obj_constr(œÅ, K) 
    obj = 0
    for i in 1:length(œÅ)-1
        obj += frobenius_norm2(sum(k * œÅ[i] * k' for k in K) - œÅ[i+1])
    end
    constr = frobenius_norm2(sum(k' * k for k in K) - I)
    return real(obj), real(constr)*1e3
end

function timeevolution_kraus(t_steps, œÅ‚ÇÄ, K)

    K = [convert.(ComplexF64, k) for k in K]

    œÅ = [œÅ‚ÇÄ]
    for t = 2:t_steps
        #push!(œÅ, Hermitian(sum([K[i]* œÅ[end] * K[i]' for i = 1:length(K)])))
        œÅ_next = Hermitian(sum(K[i]* œÅ[end] * K[i]' for i = 1:length(K)))
        push!(œÅ, œÅ_next/tr(œÅ_next))
    end
    return œÅ
end  

function rand_Kraus_w_noise(seed, w, time_span)
    Random.seed!(seed)
    
    œÅ‚ÇÄ = LiPoSID.rand_dm(2)     

    K1 = rand(2,2) + im*rand(2,2)
    K2 = rand(2,2) + im*rand(2,2)
    
    œÅ_exact = timeevolution_kraus(time_span, œÅ‚ÇÄ, [K1, K2])
    
    œÅ = [ (1 - w) * œÅ‚Çú + w * LiPoSID.rand_dm(2) for œÅ‚Çú in œÅ_exact ]
end

function rand_Kraus_w_noise(seed, w, time_span, kraus_rank)
    Random.seed!(seed)
    
    œÅ‚ÇÄ = LiPoSID.rand_dm(2)
    
    K = [rand(2,2) + im*rand(2,2) for i in 1:kras_rank]
    
    œÅ_exact = timeevolution_kraus(time_span, œÅ‚ÇÄ, K)
    
    œÅ = [ (1 - w) * œÅ‚Çú + w * LiPoSID.rand_dm(2) for œÅ‚Çú in œÅ_exact ] # adding white noise
end


# using NLopt

function minimize_local(obj, guess) # polynomial objective, and guess x candidate
    vars = variables(obj)
    
    @assert length(vars) == length(guess)

    function g(a...)
        # Converting polynomial expression to function to be minimize
        obj(vars => a)
    end
    
    model = Model(NLopt.Optimizer)

    set_optimizer_attribute(model, "algorithm", :LD_MMA)
    
    #set_silent(model)
    @variable(model, y[1:length(vars)]);
    
    for (var, init_val) in zip(y, guess)
        set_start_value(var, init_val)
    end
    
    #= if length(constr_list) > 0
        @constraint(model, constr_list)
    end =# 
    
    register(model, :g, length(y), g; autodiff = true)
    @NLobjective(model, Min, g(y...))
    JuMP.optimize!(model)
    solution = vars => map(value, y)
    
    return solution
end 

function minimize_global(obj, constr_list = [])
    optimizer = optimizer_with_attributes(Mosek.Optimizer, "QUIET" => true)
    obj_min, M = minimize(obj, constr_list, [], variables(obj), maxdegree(obj) √∑ 2, optimizer)
    
    r = get_minimizers(M)
    obj_min_vals = [obj(r[:,i]) for i=1:size(r)[2]]
    best_candidate = r[:, argmin(obj_min_vals)]
    
    minimize_local(obj, constr_list, best_candidate) 
   
end 

# using QuantumOptics

function quantum_series(basis, œÅ)
    [ DenseOperator(basis, Hermitian(œÅ[i])) for i = 1:length(œÅ) ]
end

function fidelity_series(basis, œÅ‚ÇÅ, œÅ‚ÇÇ)

    #@assert  length(œÅ‚ÇÅ) == length(œÅ‚ÇÇ)

    len_of_series = min(length(œÅ‚ÇÅ), length(œÅ‚ÇÇ))

    œÅ‚ÇÅ = quantum_series(basis, œÅ‚ÇÅ)
    œÅ‚ÇÇ = quantum_series(basis, œÅ‚ÇÇ)

    return [abs(fidelity(œÅ‚ÇÅ[i], œÅ‚ÇÇ[i])) for i in 1:len_of_series]

end

function min_fidelity_between_series(basis, œÅ1, œÅ2)

    len_of_series = length(œÅ1)

    @assert  length(œÅ2) == len_of_series

    œÅ1q = quantum_series(basis, œÅ1)
    œÅ2q = quantum_series(basis, œÅ2)
    
    minimum([abs(fidelity(œÅ1q[i], œÅ2q[i])) for i in 1:len_of_series])

end

#using TSSOS

function min2step(obj, constr)
    # obj - is objective function
    # constr - one constraint in the form of equation
    
    # extract valiables from the objective
    vars = variables(obj)

    iter = 0
    best_sol = ones(length(vars))
    
    # Perform global minimization with TSSOS package
    try
        opt,sol,data = tssos_first([obj, constr], variables(obj), maxdegree(obj)√∑2, numeq=1, solution=true, QUIET = true); 
    
        # execute higher levels of the TSSOS hierarchy
        iter = 1
        best_sol = sol

        while ~isnothing(sol)
            iter += 1
            best_sol = sol
            try
                opt,sol,data = tssos_higher!(data, solution=true, QUIET = true);
            catch
                break
            end
            
            if iter > 5
                best_sol = ones(length(vars))
                break
            end
        end
    catch
        best_sol = ones(length(vars))
    end  
   
    function g(a...)
        # Converting polynomial expression of objective to function to be minimized
        obj(vars => a)
    end
    
    function e(a...)
        # Converting polynomial expression of constraint to function to be minimize
        constr(vars => a)
    end
       
    # Create NLopt model
    model = Model(NLopt.Optimizer)

    # Set algorithm 
    set_optimizer_attribute(model, "algorithm", :LD_SLSQP) 
    
    # Set variables
    @variable(model, y[1:length(vars)]);

    # Register constraint
    register(model, :e, length(y), e; autodiff = true)
    
    @NLconstraint(model, e(y...) == 0)

    # Register objective
    register(model, :g, length(y), g; autodiff = true)
    @NLobjective(model, Min, g(y...))
    
    # Set guess
    guess = best_sol
    for (var, init_val) in zip(y, guess)
        set_start_value(var, init_val)
    end

    # Call JuMP optimization function
    JuMP.optimize!(model)

    solution = vars => map(value, y)

    return(solution, iter)
end  

function min2step(obj)
    # obj - is objective function

    # extract valiables from the objective
    vars = variables(obj)
    
    # Perform global minimization with TSSOS package
    iter = 0
    best_sol = ones(length(vars))

    try
        opt,sol,data = tssos_first(obj, variables(obj), solution=true, QUIET = true);
        # execute higher levels of the TSSOS hierarchy
        iter = 1
        best_sol = sol

        while ~isnothing(sol)
            iter += 1
            best_sol = sol
            try
                opt,sol,data = tssos_higher!(data, solution=true, QUIET = true);
            catch
                break
            end
            
            if iter > 5
                best_sol = ones(length(vars))
                break
            end
        end
    catch
        best_sol = ones(length(vars))
    end  
    
   
    function g(a...)
        # Converting polynomial expression of objective to function to be minimized
        obj(vars => a)
    end
       
    # Create NLopt model
    model = Model(NLopt.Optimizer)

    # Set algorithm 
    set_optimizer_attribute(model, "algorithm", :LD_SLSQP) 
    
    # Set variables
    @variable(model, y[1:length(vars)]);

    # Register objective
    register(model, :g, length(y), g; autodiff = true)
    @NLobjective(model, Min, g(y...))
    
    # Set guess
    guess = best_sol
    for (var, init_val) in zip(y, guess)
        set_start_value(var, init_val)
    end

    # Call JuMP optimization function
    JuMP.optimize!(model)

    solution = vars => map(value, y)

    return(solution, iter)
end  


function scaling_poly(p::Polynomial)
    X = transpose(hcat([exponents(t) for t in terms(p)]...))

    # Get the scaling via linear regression
    scaling = X \ log.(abs.(coefficients(p)))

    exp.(abs.(scaling))
end


"""
Try TSSOS, scaled TSSOS, and Homotopy Continuation to get the global minima of the polynomial
"""
function poly_min(p::Polynomial)

    # p = convert(Polynomial{true, Float64}, p)
    ################################################################################################
    #
    #   Try HomotopyContinuation
    #
    ################################################################################################

    # Find the critical points

    #minimizer_homotopy = nothing
    
    try 

        result = HomotopyContinuation.solve(differentiate.(p, variables(p)))
        critical_points = real_solutions(result)

        # Get the exact values for the exact objective function for the found critical points
        val_p = p.(critical_points)

        if length(critical_points) > 0
            global minimizer_homotopy = critical_points[argmin(val_p)]
        else global minimizer_homotopy = nothing
        end

    catch
        println(" Homotopy failed")
        global minimizer_homotopy = nothing
    #finally
        #minimizer_homotopy = nothing
    end

    #optimum = minimum(val_p)

    ################################################################################################
    #
    #   Try just plain TSSOS
    #
    ################################################################################################
    #minimizer_tssos = nothing
    try 
        opt,sol,data = tssos_first(p, variables(p), QUIET=true, solution=true, newton=false);
        previous_sol = sol

        while ~isnothing(sol)
            previous_sol = sol
            opt,sol,data = tssos_higher!(data; QUIET=true, solution=true);
        end

        global minimizer_tssos = previous_sol
    
    catch
        println(" TSSOS failed")
        global minimizer_tssos = nothing
    #finally
        #minimizer_tssos = nothing
    end

    ################################################################################################
    #
    #   Try TSSOS on polynomial with scaled variables
    #
    ################################################################################################

    # find variable scaling
    scale = scaling_poly(p)

    # scale the polynomial
    p_scaled = subs(p, variables(p) => scale .* variables(p))

    # minimize
    # minimizer_scaled_tssos = nothing

    try
        opt,sol,data = tssos_first(p_scaled, variables(p), QUIET=true, solution=true, newton=false);
        previous_sol = sol

        while ~isnothing(sol)
            previous_sol = sol
            opt,sol,data = tssos_higher!(data; QUIET=true, solution=true);
        end

        global minimizer_scaled_tssos = scale .* previous_sol
    
    catch
        println("Scaled TSSOS failed")
        global minimizer_scaled_tssos = nothing
    #finally
        #minimizer_scaled_tssos = nothing
    end

    ################################################################################################
    #
    #   Comparing
    #
    ################################################################################################
    minimizers = [[minimizer_homotopy] [minimizer_tssos] [minimizer_scaled_tssos]]
    methods = ["homotopy" "tssos" "scaled_tssos"]
    sols_bits = .!isnothing.(minimizers)

    minimizers_found = minimizers[sols_bits]
    methods_found = methods[sols_bits]

    if length(minimizers_found) > 0
        val_p = p.(minimizers_found)
        best_indx = argmin(val_p)
        best_minimizer = minimizers_found[best_indx]
        best_method = methods_found[best_indx]

    else 
        print("All methods fail !!!")
        best_minimizer = ones(length(variables(p)))
        best_method = "fail"
    end

    # best_solution = minimize_local(p, best_minimizer)

    best_solution = variables(p) => best_minimizer

    return best_solution, best_method

end
                                                                                                                                             
function sos_min_newton(p::Polynomial)

    ################################################################################################
    #
    #   Try just plain TSSOS
    #
    ################################################################################################
    #minimizer_tssos = nothing
    try 
        opt,sol,data = tssos_first(p, variables(p), QUIET=true, solution=true);
        previous_sol = sol

        while ~isnothing(sol)
            previous_sol = sol
            opt,sol,data = tssos_higher!(data; QUIET=true, solution=true);
        end

        global minimizer_tssos = previous_sol
    
    catch
        println(" TSSOS failed")
        global minimizer_tssos = nothing
    #finally
        #minimizer_tssos = nothing
    end

    ################################################################################################
    #
    #   Try TSSOS on polynomial with scaled variables
    #
    ################################################################################################

    # devide by the largest coef

    pd = maximum(abs.(coefficients(p)))

    # find variable scaling
    scale = LiPoSID.scaling_poly(pd)

    # scale the polynomial
    p_scaled = subs(pd, variables(pd) => scale .* variables(pd))

    # minimize
    # minimizer_scaled_tssos = nothing

    try
        opt,sol,data = tssos_first(p_scaled, variables(p), QUIET=true, solution=true);
        previous_sol = sol

        while ~isnothing(sol)
            previous_sol = sol
            opt,sol,data = tssos_higher!(data; QUIET=true, solution=true);
        end

        global minimizer_scaled_tssos = scale .* previous_sol
    
    catch
        println("Scaled TSSOS failed")
        global minimizer_scaled_tssos = nothing
    #finally
        #minimizer_scaled_tssos = nothing
    end

    ################################################################################################
    #
    #   Comparing
    #
    ################################################################################################
    minimizers = [[minimizer_tssos] [minimizer_scaled_tssos]]
    methods = ["tssos" "scaled_tssos"]
    sols_bits = .!isnothing.(minimizers)

    minimizers_found = minimizers[sols_bits]
    methods_found = methods[sols_bits]

    if length(minimizers_found) > 0
        val_p = p.(minimizers_found)
        @show val_p                                                                                               
        best_indx = argmin(val_p)
        best_minimizer = minimizers_found[best_indx]
        best_method = methods_found[best_indx]

    else 
        print("All methods fail !!!")
        best_minimizer = ones(length(variables(p)))
        best_method = "fail"
    end

    # best_solution = minimize_local(p, best_minimizer)

    best_solution = variables(p) => best_minimizer

    return best_solution, best_method

end                                                                                        
                                                                                    
                                                                                    
                                                                                    
function sos_min(p::Polynomial)

    ################################################################################################
    #
    #   Try just plain TSSOS
    #
    ################################################################################################
    #minimizer_tssos = nothing
    try 
        opt,sol,data = tssos_first(p, variables(p), QUIET=true, solution=true, newton=false);
        previous_sol = sol

        while ~isnothing(sol)
            previous_sol = sol
            opt,sol,data = tssos_higher!(data; QUIET=true, solution=true);
        end

        global minimizer_tssos = previous_sol
    
    catch
        println(" TSSOS failed")
        global minimizer_tssos = nothing
    #finally
        #minimizer_tssos = nothing
    end

    ################################################################################################
    #
    #   Try TSSOS on polynomial with scaled variables
    #
    ################################################################################################

    # find variable scaling
    scale = LiPoSID.scaling_poly(p)

    # scale the polynomial
    p_scaled = subs(p, variables(p) => scale .* variables(p))

    # minimize
    # minimizer_scaled_tssos = nothing

    try
        opt,sol,data = tssos_first(p_scaled, variables(p), QUIET=true, solution=true, newton=false);
        previous_sol = sol

        while ~isnothing(sol)
            previous_sol = sol
            opt,sol,data = tssos_higher!(data; QUIET=true, solution=true);
        end

        global minimizer_scaled_tssos = scale .* previous_sol
    
    catch
        println("Scaled TSSOS failed")
        global minimizer_scaled_tssos = nothing
    #finally
        #minimizer_scaled_tssos = nothing
    end

    ################################################################################################
    #
    #   Comparing
    #
    ################################################################################################
    minimizers = [[minimizer_tssos] [minimizer_scaled_tssos]]
    methods = ["tssos" "scaled_tssos"]
    sols_bits = .!isnothing.(minimizers)

    minimizers_found = minimizers[sols_bits]
    methods_found = methods[sols_bits]

    if length(minimizers_found) > 0
        val_p = p.(minimizers_found)
        best_indx = argmin(val_p)
        best_minimizer = minimizers_found[best_indx]
        best_method = methods_found[best_indx]

    else 
        print("All methods fail !!!")
        best_minimizer = ones(length(variables(p)))
        best_method = "fail"
    end

    # best_solution = minimize_local(p, best_minimizer)

    best_solution = variables(p) => best_minimizer

    return best_solution, best_method

end                                                                                  

function tssos_scaled(p::Polynomial)

    ################################################################################################
    #
    #   TSSOS on polynomial with scaled variables
    #
    ################################################################################################

    # find variable scaling
    scale = scaling_poly(p)

    # scale the polynomial
    p_scaled = subs(p, variables(p) => scale .* variables(p))

    # minimize
    # minimizer_scaled_tssos = nothing

    try
        opt,sol,data = tssos_first(p_scaled, variables(p), QUIET=true, solution=true, newton=false);
        previous_sol = sol

        while ~isnothing(sol)
            previous_sol = sol
            opt,sol,data = tssos_higher!(data; QUIET=true, solution=true);
        end

        global minimizer_scaled_tssos = scale .* previous_sol
    
    catch
        println("Scaled TSSOS failed")
        global minimizer_scaled_tssos = nothing
    end

    solution = variables(p) => minimizer_scaled_tssos

    return solution
end

function tssos_scaled(p::Polynomial, constr)

    ################################################################################################
    #
    #   TSSOS on polynomial with scaled variables
    #
    ################################################################################################

    # find variable scaling
    scale = scaling_poly(p)

    # scale the polynomial
    p_scaled = subs(p, variables(p) => scale .* variables(p))

    # minimize
    # minimizer_scaled_tssos = nothing

    try
        opt,sol,data = tssos_first([p_scaled, constr], variables(p), maxdegree(p)√∑2, numeq=1, solution=true, QUIET = true); 
        previous_sol = sol

        while ~isnothing(sol)
            previous_sol = sol
            opt,sol,data = tssos_higher!(data; QUIET=true, solution=true);
        end

        global minimizer_scaled_tssos = scale .* previous_sol
    
    catch
        println("Scaled TSSOS failed")
        global minimizer_scaled_tssos = nothing
    end

    solution = variables(p) => minimizer_scaled_tssos

    return solution
end

function local_rand_min(p)

    pd = p / maximum(abs.(coefficients(p)))

    # find variable scaling
    scale = scaling_poly(pd)

    # scale the polynomial
    p_scaled = subs(pd, variables(pd) => scale .* variables(pd))

    num_iterations = 1000

    # Initialize the best minimizer and the minimum value
    best_minimizer = nothing
    best_min_value = Inf

    num_of_variables = length(variables(pd))

    for _ in 1:num_iterations
        # Generate a random initial condition
        initial_point = rand(num_of_variables).*250 # - 250

        # Run local optimization
        result = Optim.optimize(p_scaled, initial_point, BFGS())
        #println(Optim.minimum(result))

        # Update the best minimizer if a better one is found
        if Optim.minimum(result) < best_min_value
            
            best_minimizer = Optim.minimizer(result)
            best_min_value = Optim.minimum(result)
            
        end

    end

    best_minimizer = abs.(best_minimizer) # to make gamma positive

    minimizer_scaled = scale .* best_minimizer

    solution = variables(p_scaled) => minimizer_scaled

end


#### HDF5 READING RESULTS ####

function get_seeds_and_timespan(file_name)   
    h5open(file_name,"r") do fid   # read file, preserve existing contents
        seeds = read(fid["seeds"])
        Œît = read(fid["dt"])
        t‚Çò‚Çê‚Çì = read(fid["t_max"])
        return seeds,  Œît, t‚Çò‚Çê‚Çì
    end
end

function get_noise_levels(file_name)   
    h5open(file_name,"r") do fid   # read file, preserve existing contents
        noise_levels = keys(fid["data_by_noise_level"])
        return noise_levels
    end
end

function get_variable_names(file_name, noise_level, seed)
        h5open(file_name,"r") do fid   # read file, preserve existing contents
        variable_names = keys(fid["data_by_noise_level"][string(noise_level)][string(seed)])
        return variable_names
    end
end

function get_by_name(file_name, var_name, noise_levels, seeds)
        h5open(file_name,"r") do fid # read file, preserve existing contents
        var_by_name = []
        for w in noise_levels
            current_noise_var = [ read(fid["data_by_noise_level"][string(w)][string(seed)][var_name]) for seed in seeds ]
            push!(var_by_name, current_noise_var)
        end
        return(var_by_name)
    end
end

function get_lsid(file_name, noise, seeds)
    A = get_by_name(file_name, "A", [noise], seeds)[1]
    C = get_by_name(file_name, "C", [noise], seeds)[1]
    x0 = get_by_name(file_name, "x0", [noise], seeds)[1]
    return A, C, x0
end

function get_kraus_sid(file_name, noise, seeds)  
    K1_sid = get_by_name(file_name, "K1_sid", [noise], seeds)[1]
    K2_sid = get_by_name(file_name, "K2_sid", [noise], seeds)[1]
    return K1_sid, K2_sid
end 

function get_lindblad_params(file_name, noise, key,  seeds, basis)
    H = [DenseOperator(basis, Hl) for Hl in get_by_name(file_name, "H_"*key, [noise], seeds)[1]]
    J = [DenseOperator(basis, Jl) for Jl in get_by_name(file_name, "J_"*key, [noise], seeds)[1]]
   return H, J
end

function lindblad_evolution(key, time_limit, Œît, noise_level, seed)
    time_span = [0:Œît:time_limit;]
    H_exact = DenseOperator(basis, get_by_name(file_name, "H_"*key, [noise_level], seed)[1][1])
    J_exact = DenseOperator(basis, get_by_name(file_name, "J_"*key, [noise_level], seed)[1][1])
    œÅ0 = DenseOperator(basis, get_by_name(file_name, "rho0", [noise_level], seed)[1][1])
    time, œÅ_exact_ser  = timeevolution.master(time_span, œÅ0, H_exact, [J_exact])
    œÅ = [œÅ‚Çú.data for œÅ‚Çú in œÅ_exact_ser]
end

function lindblad_evolution_data(time_span, œÅ0, H, J)
    time, œÅ_ser  = timeevolution.master(time_span, œÅ0, H, [J])
    œÅ = [œÅ‚Çú.data for œÅ‚Çú in œÅ_ser]
end


function Lindblad_time_evolution(basis, œÅ0, time_span, H, A)
    
    H = convert.(ComplexF64, H)
    
    œÅ0q = DenseOperator(basis, Hermitian(œÅ0)) 

    Hq  = DenseOperator(basis, convert.(ComplexF64,H)) # reconstructed Hamiltonian of the system
    Aq = [ DenseOperator(basis, convert.(ComplexF64, A_i))  for A_i in A ]# reconstracted Lindblad decipator
    
    time, œÅ_ser  = timeevolution.master(time_span, œÅ0q, Hq, Aq)
    
    œÅ = [œÅ‚Çú.data for œÅ‚Çú in œÅ_ser]
    
    return œÅ

end

function read_fidelity_table(file_name, fid_name, noise, seeds)
    fidelity_table = []
    h5open(file_name,"r") do fid # read file, preserve existing contents
        for seed in seeds
            push!(fidelity_table, read(fid[string(noise)][string(seed)][string(fid_name)]))
        end
        return(mapreduce(permutedims, vcat, fidelity_table))
    end
end

function get_rho_series(file_name, Œ≥)
    h5open(file_name, "r") do file
        œÅ·µß = read(file[string(Œ≥)])
        t = œÅ·µß["t"]
        œÅ‚ÇÄ‚ÇÄ = œÅ·µß["p0"]; Re_œÅ‚ÇÄ‚ÇÅ = œÅ·µß["s_re"];  Im_œÅ‚ÇÄ‚ÇÅ = œÅ·µß["s_im"]
        œÅ_series = []
        t_series = []

        for i in 1:length(t)
            œÅ·µ¢= [ œÅ‚ÇÄ‚ÇÄ[i]                      Re_œÅ‚ÇÄ‚ÇÅ[i] + im * Im_œÅ‚ÇÄ‚ÇÅ[i]
                  Re_œÅ‚ÇÄ‚ÇÅ[i] - im * Im_œÅ‚ÇÄ‚ÇÅ[i]  1 - œÅ‚ÇÄ‚ÇÄ[i]                 ]
            push!(œÅ_series, convert(Matrix{ComplexF64}, œÅ·µ¢))
            push!(t_series, convert(Float64, t[i]))
        end
        return(œÅ_series, t_series)
    end
end

function get_rho_series2(file_name, Œ≥)
    h5open(file_name, "r") do file
        œÅ·µß = read(file[string(Œ≥)])
        t = œÅ·µß["t"]
        œÅ‚ÇÄ‚ÇÄ = œÅ·µß["p0"]; Re_œÅ‚ÇÄ‚ÇÅ = œÅ·µß["s_re"];  Im_œÅ‚ÇÄ‚ÇÅ = œÅ·µß["s_im"]
        œÅ_series = []
        t_series = []

        for i in 1:length(t)
            œÅ·µ¢= [ 1-œÅ‚ÇÄ‚ÇÄ[i]                      Re_œÅ‚ÇÄ‚ÇÅ[i] + im * Im_œÅ‚ÇÄ‚ÇÅ[i]
                  Re_œÅ‚ÇÄ‚ÇÅ[i] - im * Im_œÅ‚ÇÄ‚ÇÅ[i]    œÅ‚ÇÄ‚ÇÄ[i]                 ]
            push!(œÅ_series, convert(Matrix{ComplexF64}, œÅ·µ¢))
            push!(t_series, convert(Float64, t[i]))
        end
        return(œÅ_series, t_series)
    end
end

function get_bosonic_bath_Lindblad_ME_model(file_name, Œ≥, training_length )
    h5open(file_name,"r") do fid   # read file, preserve existing contents
        H = read(fid["gamma_"*string(Œ≥)]["gt_"*string(training_length)]["H_sid_simp"])
        J_s3d = read(fid["gamma_"*string(Œ≥)]["gt_"*string(training_length)]["J_sid_simp"])
        J_simp = [convert(Matrix{ComplexF64}, J_s3d[:, :, k]) for k in axes(J_s3d, 3)]
        return H,J_simp
    end
end   

function get_bosonic_bath_Kraus_map_model(file_name, Œ≥, training_length )
    h5open(file_name,"r") do fid   # read file, preserve existing contents
        K3d = read(fid["gamma_"*string(Œ≥)]["gt_"*string(training_length)]["K_sid"])
        K = [convert(Matrix{ComplexF64}, K3d[:, :, k]) for k in axes(K3d, 3)]
        return K
    end
end   

function get_bosonic_bath_data_coupling_levels(file_name)
    h5open(file_name,"r") do fid   # read file, preserve existing contents
        coupling_levels = keys(fid)
        return coupling_levels
    end
end

function get_bosonic_bath_models_coupling_levels(file_name)
    h5open(file_name,"r") do fid   # read file, preserve existing contents
        coupling_levels = [s[7:end] for s in keys(fid)]
        return coupling_levels
    end
end

function get_bosonic_bath_models_training_durations(file_name, coupling_level)
    h5open(file_name,"r") do fid   # read file, preserve existing contents
        coupling_levels = [s[4:end] for s in keys(fid["gamma_"*string(coupling_level)])]
        return coupling_levels
    end
end

function get_bosonic_bath_lsid(file, rank_group, Œ≥_group)

    h5open(file,"r") do fid # read-only
        A = read(fid[rank_group][Œ≥_group]["A"])
        # Ac = read(fid[Œ≥_group]["Ac"])
        C = read(fid[rank_group][Œ≥_group]["C"])
        x‚ÇÄ = read(fid[rank_group][Œ≥_group]["x0"])
        n = read(fid[rank_group][Œ≥_group]["n"])
        Œ£ = read(fid[rank_group][Œ≥_group]["sigma"])
        
        return A, C, x‚ÇÄ, n, Œ£
    end
end

function get_operator(file, group, sub_group, operator_name)

    h5open(file,"r") do fid # read-only
        A = read(fid[group][sub_group][operator_name])
        return A
    end
end

function get_keys(df)
    h5open(df, "r") do file
        return keys(file)
    end
end

function get_cuts(df, Œ≥)
    h5open(df, "r") do file
        return keys(file["gamma_"*string(Œ≥)])
    end
end

function ‚äó(A, B)
    return kron(A,B)
end
     
function obj_Lindblad_from_Kraus(K, Œît, H, J)

    n = size(K[1])[1]
    @assert size(H)[1] == size(J[1])[1] == n

    K = [convert.(ComplexF64, k) for k in K]
    
    A = sum( transpose(k') ‚äó k for k in K )  
    L·¥∑ ≥·µÉ·µòÀ¢·µ• = log(A)/Œît
    
    ùìò = I(n) * 1.   
    
    U = -im*(ùìò ‚äó H - transpose(H) ‚äó ùìò)
    
    D = sum( 2*transpose(j')‚äój - ùìò‚äó(j'*j) - transpose(j)*transpose(j')‚äóùìò for j in J )/2 
    
    L·¥∏·¥π·¥±·µ•  = U + D
          
    ŒîL = L·¥∑ ≥·µÉ·µòÀ¢·µ• - L·¥∏·¥π·¥±·µ•
    
    obj = LiPoSID.frobenius_norm2(ŒîL)
            
    obj = sum(real(coef) * mon for (coef, mon) in zip(coefficients(obj), monomials(obj)))
   
    return obj
end

function direct_DMD_01XY_b4_A(œÅ)

    œÅ·µâ, œÅ·µç, œÅÀ£, œÅ ∏ = œÅ
    l·µâ = length(œÅ·µâ); l·µç = length(œÅ·µç); lÀ£ = length(œÅÀ£); l ∏ = length(œÅ ∏)
    l·µê·µÉÀ£ = min(l·µâ, l·µç,  lÀ£, l ∏)  #choose time limit by shortest series
    b·µâ = LiPoSID.bloch(œÅ·µâ[1:l·µê·µÉÀ£])
    b·µç = LiPoSID.bloch(œÅ·µç[1:l·µê·µÉÀ£])
    bÀ£ = LiPoSID.bloch(œÅÀ£[1:l·µê·µÉÀ£])
    b ∏ = LiPoSID.bloch(œÅ ∏[1:l·µê·µÉÀ£])
    Y·µâ = [b·µâ; ones(l·µâ)'] # augmented Bloch 4D vectors
    Y·µç = [b·µç; ones(l·µç)']
    YÀ£ = [bÀ£; ones(lÀ£)']
    Y ∏ = [b ∏; ones(l ∏)']

    Y·µâ‚Åª = Y·µâ[:,1:end-1]; Y·µâ‚Å∫ = Y·µâ[:,2:end]
    Y·µç‚Åª = Y·µç[:,1:end-1]; Y·µç‚Å∫ = Y·µç[:,2:end]
    YÀ£‚Åª = YÀ£[:,1:end-1]; YÀ£‚Å∫ = YÀ£[:,2:end]
    Y ∏‚Åª = Y ∏[:,1:end-1]; Y ∏‚Å∫ = Y ∏[:,2:end]

    Y‚Åª = hcat(Y·µâ‚Åª, Y·µç‚Åª, YÀ£‚Åª, Y ∏‚Åª)
    Y‚Å∫ = hcat(Y·µâ‚Å∫, Y·µç‚Å∫, YÀ£‚Å∫, Y ∏‚Å∫)

    A = Y‚Å∫ * pinv(Y‚Åª)

    return A

end

function Kraus(œÅ‚ÇÄ, E)
    œÅ = sum(K * œÅ‚ÇÄ * K' for K in E)
    œÅ = œÅ/tr(œÅ)
    return Hermitian(œÅ)
end

function choi(œÅ·µç, œÅ·µâ, œÅÀ£, œÅ ∏)
    œÅ‚ÇÅ = œÅ·µç
    œÅ‚ÇÑ = œÅ·µâ
    œÅ‚ÇÇ = œÅÀ£ + im*œÅ ∏ - (1+im)*(œÅ‚ÇÅ+œÅ‚ÇÑ)/2; # this matrix is not Hermitian
    œÅ‚ÇÉ = œÅÀ£ - im*œÅ ∏ - (1-im)*(œÅ‚ÇÅ+œÅ‚ÇÑ)/2; # this matrix is not Hermitian

    œÉ‚Çì = [ 0  1
           1  0 ]  # X gate

    Œõ = [ I   œÉ‚Çì
        œÉ‚Çì  -I ] / 2 # was -I in Niesen-Chuang (8.178)

    œá = Œõ * [ œÅ‚ÇÅ œÅ‚ÇÇ 
            œÅ‚ÇÉ œÅ‚ÇÑ ] * Œõ

    return œá
end


function operator_sum(œá)

    #@assert ishermitian(œá)

    œÉ = [ [0 1; 1 0], [0 -im; im 0], [1 0; 0 -1], [1 0; 0 1] ]
    œÉÀ£ = œÉ[1]; œÉ ∏ = œÉ[2]; œÉ·∂ª = œÉ[3]; œÉ·¥µ = œÉ[4]; 

    E‚ÇÄ = I(2)

    E‚ÇÅ = œÉÀ£  #  œÉ‚Çì  or X gate
    E‚ÇÇ = -im * œÉ ∏
    E‚ÇÉ = œÉ·∂ª

    EÃÉ = [E‚ÇÄ, E‚ÇÅ, E‚ÇÇ, E‚ÇÉ] 

    d, U = eigen(œá)

    @assert U * diagm(d) * U' ‚âà œá
    
    d = real.(d)

    E = []
    for i in 1:size(U)[2]
        if d[i] > 0 && d[i] ‚ââ 0
            E·µ¢ = sqrt(d[i]) * sum(U[j,i] * EÃÉ[j] for j in 1:size(U)[1])
            push!(E, E·µ¢)
        end
    end
    return E, d 
end

function QPT(œÅ·µç, œÅ·µâ, œÅÀ£, œÅ ∏)

    œá = choi(œÅ·µç, œÅ·µâ, œÅÀ£, œÅ ∏)

    E, d = operator_sum(œá)

    return E, d
end

function bloch4(œÅ)

    b = convert.(Float64, [ œÅ[1,2] + œÅ[2,1],
                           (œÅ[1,2] - œÅ[2,1])*im,    #œÅ[2,1] - œÅ[1,2] ?
                            œÅ[1,1] - œÅ[2,2],
                               1                 ]) #œÅ[1,1] + œÅ[2,2]  

end

function dm_b4(b) 

    œÅ = [ 1+b[3]         b[1]-im*b[2]
          b[1]+im*b[2]   1-b[3]       ]/2

end

function propagate_DMD_b4(A, œÅ‚ÇÄ, l·µê·µÉÀ£)

    œÅ = [œÅ‚ÇÄ]

    for i in 2:l·µê·µÉÀ£
        push!(œÅ, dm_b4( A * bloch4(œÅ[end])))
    end

    return œÅ

end

function DMD_step(A, œÅ‚ÇÄ)
    dm_b4(A * bloch4(œÅ‚ÇÄ))
end

#########################
#   DRIVED SYSTEM DATA
#########################

function read_drived_evolution(file_name, freq_num)
    h5open(file_name, "r") do fid
        # Access a group named "group_name"
        group = fid[string(freq_num)]
        # Read a dataset within this group
        p0 = read(group["p0"])
        p1 = read(group["p1"])
        s_re = read(group["s_re"])
        s_im = read(group["s_im"])
        t = read(group["t"])

        n = length(t)
        œÅ = [zeros(2, 2)+im*zeros(2, 2) for _ in 1:n]

        for i in [1:n;]
            œÅ[i] = Hermitian([ p1[i]               s_re[i]+im*s_im[i]
                               s_re[i]-im*s_im[i]  p0[i]              ])
        end

        return t, œÅ
    end
end

######################################
# Constrained optimization with JuMP
######################################

# Helper function to suppress output
function suppress_output(f, args...; kwargs...)
    original_stdout = stdout
    original_stderr = stderr
    redirect_stdout(devnull) do
        redirect_stderr(devnull) do
            return f(args...; kwargs...)
        end
    end
end

# Define the function jump_constrained
function jump_constrained(obj::Polynomial, constr::Vector{<:Polynomial})
    try
        # Extract variables from the objective and constraints
        obj_vars = variables(obj)
        constr_vars = unique(vcat(variables.(constr)...))
        all_vars = unique(vcat(obj_vars, constr_vars))
        n = length(all_vars)
        
        # Create the optimization model
        model = Model(Ipopt.Optimizer)
        
        # Define the JuMP variables
        @variable(model, x[1:n])
        
        # Create a function to evaluate the polynomial
        function evaluate_poly(poly, var_map)
            expr = zero(x[1]) # Initialize to zero with the type of x[1]
            for (term, coeff) in zip(terms(poly), coefficients(poly))
                term_expr = coeff
                for (v, exp) in zip(variables(term), exponents(term))
                    term_expr *= var_map[v]^exp
                end
                expr += term_expr
            end
            return expr
        end
        
        # Map the polynomial variables to JuMP variables
        var_map = Dict(v => x[i] for (i, v) in enumerate(all_vars))
        
        # Define the objective function
        obj_expr = evaluate_poly(obj, var_map)
        @NLobjective(model, Min, obj_expr)
        
        # Define the constraints
        for c in constr
            c_expr = evaluate_poly(c, var_map)
            @NLconstraint(model, c_expr >= 0)
        end
        
        # Solve the optimization problem
        suppress_output(JuMP.optimize!, model)
        
        # Get the results
        optimal_solution = value.(x)
        optimal_value = objective_value(model)
        status = termination_status(model)
        
        return optimal_solution, optimal_value, status
    catch e
        println("An error occurred: ", e)
        return nothing, nothing, :Error
    end
end

end
